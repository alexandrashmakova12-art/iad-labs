{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ngBv7xMMbnW",
        "outputId": "4178c9d1-ded4-4e95-acd8-08f092732888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "CSV shape: (34130, 5)\n",
            "Columns: ['дів \"\"Підлісний\"\"', ' що поряд із ЧАЕС', ' відділяє кілька кілометрів. За словами Геращенка', ' загрози для ЧАЕС і ядерних сховищ немає. Радіаційний фон не змінився.\"', 'True']\n",
            "Using text column:  що поряд із ЧАЕС\n",
            "Raw texts: 34130\n",
            "Final training samples: 20000\n",
            "Vocab size: 20000\n",
            "Trainable params: 5537568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | train loss/token 7.1428 | val 6.1574\n",
            "Epoch 2/3 | train loss/token 5.2500 | val 4.0803\n",
            "Epoch 3/3 | train loss/token 3.1580 | val 2.2625\n",
            "\n",
            "--- GENERATION EXAMPLES ---\n",
            "\n",
            "PROMPT: сьогодні в україні\n",
            "GEN   : сьогодні в україні в в режимі\n",
            "\n",
            "PROMPT: економіка країни\n",
            "GEN   : економіка країни відправив пасажирських зробіть численні тиснути\n",
            "\n",
            "PROMPT: уряд заявив\n",
            "GEN   : уряд заявив радник радник оп оп оп оп пише\n",
            "\n",
            "PROMPT: війна триває\n",
            "GEN   : війна триває триває триває триває триває триває спочатку триває історію біженцям\n"
          ]
        }
      ],
      "source": [
        "import os, re, math, random\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Reproducibility + device\n",
        "# ----------------------------\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Завантаження датасету\n",
        "# ----------------------------\n",
        "CSV_PATH = \"news_data.csv\"   # файл, який ти завантажила\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"CSV shape:\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# Пошук текстової колонки\n",
        "CANDIDATE_TEXT_COLS = [\"text\", \"content\", \"body\", \"article\", \"news\", \"description\"]\n",
        "text_col = None\n",
        "for c in CANDIDATE_TEXT_COLS:\n",
        "    if c in df.columns:\n",
        "        text_col = c\n",
        "        break\n",
        "\n",
        "if text_col is None:\n",
        "    obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
        "    if not obj_cols:\n",
        "        raise ValueError(\"No text column found.\")\n",
        "    text_col = obj_cols[0]\n",
        "\n",
        "print(\"Using text column:\", text_col)\n",
        "\n",
        "texts_raw = df[text_col].dropna().astype(str).tolist()\n",
        "print(\"Raw texts:\", len(texts_raw))\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Cleaning + chunking\n",
        "# ----------------------------\n",
        "UA_LETTERS = \"а-яіїєґ\"\n",
        "UA_LETTERS_UP = \"А-ЯІЇЄҐ\"\n",
        "\n",
        "def clean_text(t: str) -> str:\n",
        "    t = t.replace(\"\\u00A0\", \" \")\n",
        "    t = re.sub(r\"<.*?>\", \" \", t)\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"@\\S+\", \" \", t)\n",
        "    t = re.sub(rf\"[^ {UA_LETTERS}{UA_LETTERS_UP}’'\\-]\", \" \", t)\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "cleaned = [clean_text(t) for t in texts_raw]\n",
        "cleaned = [t for t in cleaned if len(t) >= 40]\n",
        "\n",
        "def chunk_text(t, chunk_words=80, stride=60):\n",
        "    words = t.split()\n",
        "    if len(words) <= chunk_words:\n",
        "        return [t]\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        part = words[i:i+chunk_words]\n",
        "        if len(part) >= 30:\n",
        "            chunks.append(\" \".join(part))\n",
        "        i += stride\n",
        "    return chunks\n",
        "\n",
        "texts = []\n",
        "for t in cleaned:\n",
        "    texts.extend(chunk_text(t))\n",
        "\n",
        "# Обмеження для швидшого навчання\n",
        "texts = texts[:20000]\n",
        "print(\"Final training samples:\", len(texts))\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Vocabulary\n",
        "# ----------------------------\n",
        "MAX_VOCAB = 20000\n",
        "specials = [\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
        "\n",
        "counter = Counter()\n",
        "for t in texts:\n",
        "    counter.update(t.split())\n",
        "\n",
        "most_common = counter.most_common(MAX_VOCAB - len(specials))\n",
        "itos_list = specials + [w for w, _ in most_common]\n",
        "stoi = {w: i for i, w in enumerate(itos_list)}\n",
        "\n",
        "PAD_IDX = stoi[\"[PAD]\"]\n",
        "UNK_IDX = stoi[\"[UNK]\"]\n",
        "BOS_IDX = stoi[\"[BOS]\"]\n",
        "EOS_IDX = stoi[\"[EOS]\"]\n",
        "\n",
        "vocab_size = len(stoi)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Encode + LM pairs\n",
        "# ----------------------------\n",
        "MAX_LEN = 96\n",
        "\n",
        "def encode_with_specials(text):\n",
        "    ids = [stoi.get(w, UNK_IDX) for w in text.split()]\n",
        "    ids = ids[:MAX_LEN - 2]\n",
        "    return [BOS_IDX] + ids + [EOS_IDX]\n",
        "\n",
        "def make_lm_pair(seq):\n",
        "    return seq[:-1], seq[1:]\n",
        "\n",
        "def pad_seq(seq, max_len=MAX_LEN-1):\n",
        "    seq = seq[:max_len]\n",
        "    if len(seq) < max_len:\n",
        "        seq = seq + [PAD_IDX] * (max_len - len(seq))\n",
        "    return torch.tensor(seq, dtype=torch.long)\n",
        "\n",
        "encoded = [encode_with_specials(t) for t in texts]\n",
        "pairs = [make_lm_pair(s) for s in encoded]\n",
        "\n",
        "X = torch.stack([pad_seq(x) for x, _ in pairs])\n",
        "Y = torch.stack([pad_seq(y) for _, y in pairs])\n",
        "\n",
        "class LMDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "dataset = LMDataset(X, Y)\n",
        "\n",
        "val_size = int(0.1 * len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size],\n",
        "                                generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "BATCH_SIZE = 64   # ↓ було 128\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Decoder-only Transformer\n",
        "# ----------------------------\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class TransformerDecoderLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.pos = PositionalEncoding(emb_dim)\n",
        "        layer = nn.TransformerDecoderLayer(\n",
        "            d_model=emb_dim, nhead=4,\n",
        "            dim_feedforward=256, batch_first=True\n",
        "        )\n",
        "        self.decoder = nn.TransformerDecoder(layer, num_layers=2)\n",
        "        self.fc = nn.Linear(emb_dim, vocab_size)\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def causal_mask(self, T, device):\n",
        "        m = torch.triu(torch.ones(T, T, device=device), diagonal=1)\n",
        "        return m.masked_fill(m == 1, float(\"-inf\"))\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.pos(self.emb(x))\n",
        "        T = x.size(1)\n",
        "        mask = self.causal_mask(T, x.device)\n",
        "        out = self.decoder(\n",
        "            emb, emb,\n",
        "            tgt_mask=mask,\n",
        "            tgt_key_padding_mask=(x == self.pad_idx),\n",
        "            memory_key_padding_mask=(x == self.pad_idx)\n",
        "        )\n",
        "        return self.fc(out)\n",
        "\n",
        "model = TransformerDecoderLM(vocab_size, 128, PAD_IDX).to(device)\n",
        "print(\"Trainable params:\", sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Training\n",
        "# ----------------------------\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def run_epoch(model, loader, train=True):\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, total_tokens = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        B, T, V = logits.shape\n",
        "        loss = criterion(logits.view(B*T, V), y.view(B*T))\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        tokens = (y != PAD_IDX).sum().item()\n",
        "        total_loss += loss.item() * tokens\n",
        "        total_tokens += tokens\n",
        "    return total_loss / total_tokens\n",
        "\n",
        "EPOCHS = 3\n",
        "for ep in range(1, EPOCHS + 1):\n",
        "    tr = run_epoch(model, train_loader, True)\n",
        "    va = run_epoch(model, val_loader, False)\n",
        "    print(f\"Epoch {ep}/{EPOCHS} | train loss/token {tr:.4f} | val {va:.4f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Generation\n",
        "# ----------------------------\n",
        "itos = {i: w for w, i in stoi.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(prompt, max_new_tokens=40, temperature=1.1):\n",
        "    model.eval()\n",
        "    prompt = clean_text(prompt)\n",
        "    ids = [BOS_IDX] + [stoi.get(w, UNK_IDX) for w in prompt.split()]\n",
        "    ids = ids[:MAX_LEN-2]\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        x = torch.tensor([ids], device=device)\n",
        "        logits = model(x)[0, -1] / temperature\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        next_id = torch.multinomial(probs, 1).item()\n",
        "        ids.append(next_id)\n",
        "        if next_id == EOS_IDX:\n",
        "            break\n",
        "\n",
        "    return \" \".join(itos[i] for i in ids if i not in (PAD_IDX, BOS_IDX, EOS_IDX))\n",
        "\n",
        "print(\"\\n--- GENERATION EXAMPLES ---\")\n",
        "for p in [\"сьогодні в україні\", \"економіка країни\", \"уряд заявив\", \"війна триває\"]:\n",
        "    print(\"\\nPROMPT:\", p)\n",
        "    print(\"GEN   :\", generate(p))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}